# Why is Deep Learning taking off?

<img src=https://github.com/lmoham/deep-learning-specialization/blob/main/1.%20Neural%20Networks%20and%20Deep%20Learning/images/3scale.jpg width="500">

* Data scaling and machine learning:
  * Improving performance of already existing algos (SVM, Log. regression, etc.) becomes hard to do, even with more data
  * With NNs, the more (labeled) data, the better
  * Early on (i.e. w/ less (labeled) data), performance depends on skill
    * A highly motivated person can create an SVM that performs better than NNs
    * But skill can only take you so far, and if you want better performance (e.g. more accurate predictions, etc.)...
      * ...then it is wise to use NNs to leverage the large amount of data to its fullest potential
   
<img src=https://github.com/lmoham/deep-learning-specialization/blob/main/1.%20Neural%20Networks%20and%20Deep%20Learning/images/3dlprogress.jpg width="500">

* Deep Learning progress:
  * Much has progressed in 3 areas - Data (the greater the amount, the more powerful the model), Computation (ways to make ML faster), Algorithms (ways to make NN faster)
    * Example for algorithm - Using ReLU instead of sigmoid means we no longer have to work with near-zero gradients for positive examples (where parameters change slowly)
    * Faster computation = quicker iterations = improve ideas much faster
