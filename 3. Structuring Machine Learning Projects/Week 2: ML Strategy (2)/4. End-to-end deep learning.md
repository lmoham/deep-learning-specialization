# What is end-to-end deep learning?

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/3.%20Structuring%20Machine%20Learning%20Projects/images/week2/4.1.0.jpg" width="500"/>

* Example: There are many steps to take in order to convert an audio file into a transcript
  * With end-to-end learning, you go straight from audio to transcript
    * Some may go from audio to phoneme and then to transcript - a somewhat end-to-end model
  * Works well when you have large amounts of data. Otherwise you are better off with the traditional route

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/3.%20Structuring%20Machine%20Learning%20Projects/images/week2/4.1.1.jpg" width="500"/>

* Face recognition can be done end-to-end, but its best done in 2 separate tasks
  * These tasks are: Locating the face of an individual and zooming into the face
    * We have plenty of data of just people in photos (to train face finding) and zoomed in photos of peoples' faces (recognition)...
    * ...but not enough data of people appearing in the camera in different ways (if we did, then end-to-end could be possible)

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/3.%20Structuring%20Machine%20Learning%20Projects/images/week2/4.1.2.jpg" width="500"/>

* Possible to do end-to-end in the first example because there are plenty of english sentences translated to french
* If you don't have as much data, then separating the task into 2 subtasks will work much better, as seen in the child age estimation model

# Whether to use end-to-end deep learning

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/3.%20Structuring%20Machine%20Learning%20Projects/images/week2/4.2.0.jpg" width="500"/>

* Some pros and cons of end-to-end learning
* Hand-designing features can be both a blessing and a curse
  * If well designed, your algorithm will perform much better, and vice versa
  * Hand-designed features force your algorithm to think in a particular way, rather than develop its own understanding
      * It is kind of a double-edged sword

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/3.%20Structuring%20Machine%20Learning%20Projects/images/week2/4.2.1.jpg" width="500"/>

* In this case, the hand-designed features work REALLY well
  * It is unclear whether an end-to-end model could work as well (but of course, if you had enough data, you could theoretically create one)
  * Identify the subtasks where you can get tons of data for (in this case, car and people images)
