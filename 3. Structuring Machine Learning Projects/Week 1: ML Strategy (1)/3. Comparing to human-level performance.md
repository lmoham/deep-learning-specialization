# Why human-level performance?

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/3.%20Structuring%20Machine%20Learning%20Projects/images/week1/3.1.0.jpg" width="500"/>

* Bayes' optimal error - The level of error obtained with a perfect mapping of x to y (impossible to surpass)
  * Some inputs are just too noisy to identify correctly - this is why there is always some level of error to be expected
* Improving before human-level performance can happen quickly, but then slows down once you've reached or passed it. Why?
  1. Human-level performance isn't that far from Bayes' optimal error, meaning there isn't much room for improvement 
  2. Tools that are used to reach human-level performance are harder to use beyond it

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/3.%20Structuring%20Machine%20Learning%20Projects/images/week1/3.1.1.jpg" width="500"/>

* Humans are good at lots of tasks
  * If an ML model can't do it, why even bother? You can just get someone to do it

# Avoidable bias

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/3.%20Structuring%20Machine%20Learning%20Projects/images/week1/3.2.0.jpg" width="500"/>

* We can use human-level error as a proxy for Bayes' optimal error
  * Since they are close together
  * Then, if training error is far from our proxy
    * Work to fix the avoidable bias problem 
  * If the training error to test error is more significant
    * Work to fix the variance problem

# Understanding human-level performance

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/3.%20Structuring%20Machine%20Learning%20Projects/images/week1/3.3.0.jpg" width="500"/>

* What exactly does human-level error mean, if performance differs between humans?
  * One interpretation: Since we want to approximate BOE (bayes' optimal error) we select the best possible one (in this case, 0.5%)
  * Another: Perhaps there is a case where surpassing 1% is good enough? In that case, use it.

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/3.%20Structuring%20Machine%20Learning%20Projects/images/week1/3.3.1.jpg" width="500"/>

* In cases where training error / dev error is relatively far from all possible BOEs, selecting our BOE doesn't matter
  * Focus should be on solving the bias problem (or even the variance problem, whichever one applies)
* When you get really close to optimal performance, selecting the best BOE should be done
  * This is because you want to aim for the best performance possible
    * (not that you don't want that for the other models...
    * ...but they weren't performing as well, which is why we opt for it here)

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/3.%20Structuring%20Machine%20Learning%20Projects/images/week1/3.3.2.jpg" width="500"/>

* Difference between BOE and training error deals with the avoidable bias problem
* Difference between training error and dev error involves the variance problem
* Understanding the right BOE for our problem helps us to see which problem we need to deal with

# Surpassing human-level performance

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/3.%20Structuring%20Machine%20Learning%20Projects/images/week1/3.4.0.jpg" width="500"/>

* What if the training error is less than BOE?
  * It could mean we are either overfitting or the BOE is lower than expected
  * Unclear whether we have a bias or variance problem
  * Since BOE is based on human intuition and the current BOE is higher than what was achieved...
  * ...it becomes unclear on how to progress 

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/3.%20Structuring%20Machine%20Learning%20Projects/images/week1/3.4.1.jpg" width="500"/>

* Left: 4 examples of applications that have surpasssed human-level performance
  * What they have in common: Large amounts of structured data and don't involve natural perceptions
* Right: Examples of machines surpassing human-level performance in natural perception tasks 
  * The challenge to reach this goal is more difficult compared to the previous examples

# Improving your model performance

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/3.%20Structuring%20Machine%20Learning%20Projects/images/week1/3.5.0.jpg" width="500"/>

* For your supervised learning model to work well you assume that:
  1. Low avoidable bias
  2. Low variance

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/3.%20Structuring%20Machine%20Learning%20Projects/images/week1/3.5.1.jpg" width="500"/>

* Avoidable bias is measured between BOE and training error
* Variance is measured between training error and dev error
* Includes some approaches on how to deal with avoidable bias and variance
