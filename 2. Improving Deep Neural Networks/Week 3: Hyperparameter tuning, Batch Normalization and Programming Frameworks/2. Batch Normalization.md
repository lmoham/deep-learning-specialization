# Normalizing activations in a network

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/2.%20Improving%20Deep%20Neural%20Networks/images/week3/2.1.0.jpg" width="500"/>

* Normalizing our dataset makes our gradient descent more efficient; Can we do that for activations?
* The answer is yes and it is typically applied to z (i.e. before activations are applied)

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/2.%20Improving%20Deep%20Neural%20Networks/images/week3/2.1.1.jpg" width="500"/>

* Normalization involves subtracting the mean then dividing by the variance
* However, if we were to use a function like sigmoid, we don't want to limit our values to a particular range
  * Gamma and beta allows us to control this
    * This way, we get the benefit of normalization, while also keeping our range of possible values realistic

# Fitting Batch Norm into a neural network

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/2.%20Improving%20Deep%20Neural%20Networks/images/week3/2.2.0.jpg" width="500"/>

* How it works: 
  1. Calculate Z[l] based on w[l] and b[l]
  2. Calculate Z norm[l]
  3. Calculate a[l] based on Z norm[l]
* When you do backprop, you now have to update 2 additional parameters: gamma and beta

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/2.%20Improving%20Deep%20Neural%20Networks/images/week3/2.2.1.jpg" width="500"/>

* Mini-batch implementation
* During the normalization step, you subtract by the mean
  * This means adding b[l] is pointless, because the mean subtraction takes that away
  * We therefore drop it, and beta will function as our bias instead of b

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/2.%20Improving%20Deep%20Neural%20Networks/images/week3/2.2.2.jpg" width="500"/>

* Pseudo-code of mini-batch normalization w/ gradient descent

# Why does Batch Norm work?

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/2.%20Improving%20Deep%20Neural%20Networks/images/week3/2.3.0.jpg" width="500"/>

* Let's say we train a cat predictor, but it only predicts black cats, and you want to predict colorful cats
  * Covariate shift - A change in the data distribution
  * Our model maps x (input) to y (prediction), therefore if x changes, we might need to retrain the model

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/2.%20Improving%20Deep%20Neural%20Networks/images/week3/2.3.1.jpg" width="500"/>

* Later layers in a NN deal with the covariate shift problem all the time (previous activations always change in value)
* With batch norm, we reduce the amount that the activations shift around in the earlier layers
  * It "stabalizes" activations for the later layers to calculate
  * The changes still happen, but it happens less

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/2.%20Improving%20Deep%20Neural%20Networks/images/week3/2.3.2.jpg" width="500"/>

* Because we use mean / variance for a particular batch, we are adding noise to Z
  * This is because they will definitely vary between batches
  * As a result, it slightly regularizes our activations
  * The bigger the mini-batch, the weaker the regularization effect
  * Do not use for regularizing - Add dropout if you want that

# Batch Norm at test time

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/2.%20Improving%20Deep%20Neural%20Networks/images/week3/2.4.0.jpg" width="500"/>

* Now you have a trained model and you want to test it out. How to get the mean and variance for 1 test example?
* Answer: Estimated weighted averages, where we get a value for mean and variance, based on the mean and variances for each batch
