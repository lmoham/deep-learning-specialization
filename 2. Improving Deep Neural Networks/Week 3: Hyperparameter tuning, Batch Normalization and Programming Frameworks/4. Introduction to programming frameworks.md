# Deep learning frameworks

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/2.%20Improving%20Deep%20Neural%20Networks/images/week3/4.1.0.jpg" width="500"/>

* As we dive deeper into more complex topics, matrix multiplication can become extremely inefficient by hand
* Thankfully, there exist many different frameworks that make complex ML model implementation easy
* Some guidelines on how to pick a framework
  * Also consider what kind of language you want to use (Python, Java, C++, etc.)

# Tensorflow

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/2.%20Improving%20Deep%20Neural%20Networks/images/week3/4.2.0.jpg" width="500"/>

* We first try to minimize (w - 25)<sup>2</sup> (hint: w = 5)
* The structure in tensorflow used to solve this is similar to one used in more complicated scenarios

<img src="https://github.com/lmoham/deep-learning-specialization/blob/main/2.%20Improving%20Deep%20Neural%20Networks/images/week3/4.2.1.jpg" width="500"/>

* Coded implementation of our cost function, along with gradient descent
* Computational graph at the top-right, showing what is happening in our tensorflow model
* We only need to concern ourselves with the forward-prop portion of our model
  * Backprop is handled automatically by the framework
* We can break this down into several steps:
  1. Create x and w as tf variables (x is a placeholder for our inputs)
  2. Initialize our cost function
  3. Put this cost function into our training model
  4. Initialize our tf variables, then run the model
